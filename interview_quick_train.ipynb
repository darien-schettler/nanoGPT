{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nanoGPT â€“ Quick Training Notebook\n",
    "\n",
    "Use this notebook to run a short training loop on Tiny Shakespeare (character-level).\n",
    "\n",
    "Workflow:\n",
    "1) Run \"Setup\" to detect device and branch.\n",
    "2) Run \"Prepare data\" once (creates `data/shakespeare_char/train.bin`, `val.bin`).\n",
    "3) Run \"Train\" to see losses (train/val) for a very short run.\n",
    "4) If you edit `model.py`, rerun the \"Reload model & Rebuild\" cell to pick up changes (module reload).\n",
    "\n",
    "Configuration:\n",
    "- Small model (4 layers, 4 heads, 128 embedding dim)\n",
    "- Fast training (300 iterations)\n",
    "- No DDP, no `torch.compile` for simplicity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Git branch: master\n"
     ]
    }
   ],
   "source": [
    "# Setup: imports, device, utils\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure repository root on sys.path\n",
    "repo_root = Path.cwd()\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.append(str(repo_root))\n",
    "\n",
    "\n",
    "def detect_device() -> str:\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        return 'mps'\n",
    "    return 'cpu'\n",
    "\n",
    "\n",
    "def current_branch() -> str:\n",
    "    try:\n",
    "        out = subprocess.check_output([\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\"], cwd=repo_root)\n",
    "        return out.decode().strip()\n",
    "    except Exception:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "def checkout_branch(name: str) -> None:\n",
    "    \"\"\"Optionally switch branches from within the notebook, then reload model in a later cell.\"\"\"\n",
    "    subprocess.check_call([\"git\", \"checkout\", name], cwd=repo_root)\n",
    "    print(f\"Switched to branch: {name}\")\n",
    "\n",
    "\n",
    "device = detect_device()\n",
    "torch.manual_seed(1337)\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Git branch: {current_branch()}\")\n",
    "\n",
    "# Plot style\n",
    "plt.style.use('ggplot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiny Shakespeare binaries already exist.\n",
      "- /Users/darienschettler/PycharmProjects/nanoGPT-1/data/shakespeare_char/train.bin\n",
      "- /Users/darienschettler/PycharmProjects/nanoGPT-1/data/shakespeare_char/val.bin\n"
     ]
    }
   ],
   "source": [
    "# Prepare data: Tiny Shakespeare (character-level)\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "DATA_DIR = repo_root / \"data\" / \"shakespeare_char\"\n",
    "TRAIN_BIN = DATA_DIR / \"train.bin\"\n",
    "VAL_BIN = DATA_DIR / \"val.bin\"\n",
    "\n",
    "if TRAIN_BIN.exists() and VAL_BIN.exists():\n",
    "    print(\"Tiny Shakespeare binaries already exist.\")\n",
    "    print(f\"- {TRAIN_BIN}\")\n",
    "    print(f\"- {VAL_BIN}\")\n",
    "else:\n",
    "    print(\"Preparing Tiny Shakespeare dataset (this downloads ~1MB and preprocesses)...\")\n",
    "    subprocess.check_call([sys.executable, str(DATA_DIR / \"prepare.py\")], cwd=repo_root)\n",
    "    assert TRAIN_BIN.exists() and VAL_BIN.exists(), \"Data preparation failed to produce train.bin/val.bin\"\n",
    "    print(\"Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training utilities: tiny config & dataloader\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Small, fast config suitable for CPU/MPS/GPU\n",
    "block_size = 64\n",
    "batch_size = 16\n",
    "n_layer = 4\n",
    "n_head = 4\n",
    "n_embd = 128\n",
    "dropout = 0.0\n",
    "max_iters = 5000\n",
    "log_interval = 10\n",
    "eval_interval = 50\n",
    "eval_iters = 20\n",
    "learning_rate = 3e-4\n",
    "weight_decay = 0.1\n",
    "\n",
    "# Dataloader: same shape semantics as train.py\n",
    "DATA_MEM_TRAIN = str(TRAIN_BIN)\n",
    "DATA_MEM_VAL = str(VAL_BIN)\n",
    "\n",
    "def get_batch(split: str) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    data = np.memmap(DATA_MEM_TRAIN if split == 'train' else DATA_MEM_VAL, dtype=np.uint16, mode='r')\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(model) -> dict[str, float]:\n",
    "    model.eval()\n",
    "    out = {}\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean().item()\n",
    "    model.train()\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model from: /Users/darienschettler/PycharmProjects/nanoGPT-1/model.py\n",
      "number of parameters: 0.80M\n",
      "Model built.\n"
     ]
    }
   ],
   "source": [
    "# Reload model & Rebuild (run this after switching branches or editing model.py)\n",
    "import importlib\n",
    "import model as model_module\n",
    "importlib.reload(model_module)\n",
    "from model import GPTConfig, GPT\n",
    "\n",
    "print(f\"Using model from: {model_module.__file__}\")\n",
    "\n",
    "# Infer vocab size from dataset meta if present, fallback to GPT-2 padded size\n",
    "import pickle\n",
    "meta_path = DATA_DIR / 'meta.pkl'\n",
    "meta_vocab_size = None\n",
    "if meta_path.exists():\n",
    "    with open(meta_path, 'rb') as f:\n",
    "        meta = pickle.load(f)\n",
    "    meta_vocab_size = int(meta.get('vocab_size', 50304))\n",
    "\n",
    "vocab_size = meta_vocab_size if meta_vocab_size is not None else 50304\n",
    "\n",
    "cfg = GPTConfig(\n",
    "    block_size=block_size,\n",
    "    vocab_size=vocab_size,\n",
    "    n_layer=n_layer,\n",
    "    n_head=n_head,\n",
    "    n_embd=n_embd,\n",
    "    dropout=dropout,\n",
    "    bias=True,\n",
    ")\n",
    "model = GPT(cfg).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "print(\"Model built.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[init] train loss: 4.2131, val loss: 4.2104\n",
      "iter   10 | loss 3.4298\n",
      "iter   20 | loss 3.2970\n",
      "iter   30 | loss 3.0820\n",
      "iter   40 | loss 2.9281\n",
      "iter   50 | loss 2.8289\n",
      "[eval] iter   50 | train 2.8189 | val 2.8397\n",
      "iter   60 | loss 2.7658\n",
      "iter   70 | loss 2.6816\n",
      "iter   80 | loss 2.6432\n",
      "iter   90 | loss 2.6596\n",
      "iter  100 | loss 2.6114\n",
      "[eval] iter  100 | train 2.6455 | val 2.6430\n",
      "iter  110 | loss 2.5524\n",
      "iter  120 | loss 2.6348\n",
      "iter  130 | loss 2.5236\n",
      "iter  140 | loss 2.5778\n",
      "iter  150 | loss 2.5656\n",
      "[eval] iter  150 | train 2.5474 | val 2.5453\n",
      "iter  160 | loss 2.5664\n",
      "iter  170 | loss 2.4794\n",
      "iter  180 | loss 2.5529\n",
      "iter  190 | loss 2.4935\n",
      "iter  200 | loss 2.5063\n",
      "[eval] iter  200 | train 2.4903 | val 2.4921\n",
      "iter  210 | loss 2.4349\n",
      "iter  220 | loss 2.4652\n",
      "iter  230 | loss 2.4623\n",
      "iter  240 | loss 2.4486\n",
      "iter  250 | loss 2.4650\n",
      "[eval] iter  250 | train 2.4388 | val 2.4669\n",
      "iter  260 | loss 2.4160\n",
      "iter  270 | loss 2.3521\n",
      "iter  280 | loss 2.4725\n",
      "iter  290 | loss 2.4091\n",
      "iter  300 | loss 2.4700\n",
      "[eval] iter  300 | train 2.4400 | val 2.4471\n",
      "iter  310 | loss 2.3924\n",
      "iter  320 | loss 2.3908\n",
      "iter  330 | loss 2.4148\n",
      "iter  340 | loss 2.4573\n",
      "iter  350 | loss 2.3461\n",
      "[eval] iter  350 | train 2.4079 | val 2.4022\n",
      "iter  360 | loss 2.4141\n",
      "iter  370 | loss 2.3562\n",
      "iter  380 | loss 2.3745\n",
      "iter  390 | loss 2.3563\n",
      "iter  400 | loss 2.3828\n",
      "[eval] iter  400 | train 2.3629 | val 2.3722\n",
      "iter  410 | loss 2.3437\n",
      "iter  420 | loss 2.3514\n",
      "iter  430 | loss 2.3430\n",
      "iter  440 | loss 2.3635\n",
      "iter  450 | loss 2.3295\n",
      "[eval] iter  450 | train 2.3647 | val 2.3680\n",
      "iter  460 | loss 2.3312\n",
      "iter  470 | loss 2.3180\n",
      "iter  480 | loss 2.3674\n",
      "iter  490 | loss 2.3769\n",
      "iter  500 | loss 2.3308\n",
      "[eval] iter  500 | train 2.3326 | val 2.3334\n",
      "iter  510 | loss 2.3015\n",
      "iter  520 | loss 2.2709\n",
      "iter  530 | loss 2.3515\n",
      "iter  540 | loss 2.3315\n",
      "iter  550 | loss 2.3722\n",
      "[eval] iter  550 | train 2.3007 | val 2.3222\n",
      "iter  560 | loss 2.3191\n",
      "iter  570 | loss 2.3248\n",
      "iter  580 | loss 2.3160\n",
      "iter  590 | loss 2.3024\n",
      "iter  600 | loss 2.3236\n",
      "[eval] iter  600 | train 2.2895 | val 2.3007\n",
      "iter  610 | loss 2.2824\n",
      "iter  620 | loss 2.2781\n",
      "iter  630 | loss 2.2690\n",
      "iter  640 | loss 2.2420\n",
      "iter  650 | loss 2.2419\n",
      "[eval] iter  650 | train 2.2749 | val 2.2859\n",
      "iter  660 | loss 2.3176\n",
      "iter  670 | loss 2.2840\n",
      "iter  680 | loss 2.2049\n",
      "iter  690 | loss 2.2464\n",
      "iter  700 | loss 2.2281\n",
      "[eval] iter  700 | train 2.2443 | val 2.2749\n",
      "iter  710 | loss 2.2993\n",
      "iter  720 | loss 2.3255\n",
      "iter  730 | loss 2.2022\n",
      "iter  740 | loss 2.1963\n",
      "iter  750 | loss 2.2202\n",
      "[eval] iter  750 | train 2.2472 | val 2.2566\n",
      "iter  760 | loss 2.3303\n",
      "iter  770 | loss 2.2212\n",
      "iter  780 | loss 2.2476\n",
      "iter  790 | loss 2.1896\n",
      "iter  800 | loss 2.2447\n",
      "[eval] iter  800 | train 2.1932 | val 2.2199\n",
      "iter  810 | loss 2.1644\n",
      "iter  820 | loss 2.1416\n",
      "iter  830 | loss 2.2063\n",
      "iter  840 | loss 2.1916\n",
      "iter  850 | loss 2.1506\n",
      "[eval] iter  850 | train 2.1603 | val 2.1952\n",
      "iter  860 | loss 2.2029\n",
      "iter  870 | loss 2.0900\n",
      "iter  880 | loss 2.1431\n",
      "iter  890 | loss 2.1871\n",
      "iter  900 | loss 2.2234\n",
      "[eval] iter  900 | train 2.1575 | val 2.2017\n",
      "iter  910 | loss 2.0778\n",
      "iter  920 | loss 2.1739\n",
      "iter  930 | loss 2.1330\n",
      "iter  940 | loss 2.1490\n",
      "iter  950 | loss 2.1366\n",
      "[eval] iter  950 | train 2.1300 | val 2.1666\n",
      "iter  960 | loss 2.0425\n",
      "iter  970 | loss 2.0299\n",
      "iter  980 | loss 2.0926\n",
      "iter  990 | loss 2.0603\n",
      "iter 1000 | loss 2.1218\n",
      "[eval] iter 1000 | train 2.1120 | val 2.1613\n",
      "iter 1010 | loss 2.0873\n",
      "iter 1020 | loss 2.0133\n",
      "iter 1030 | loss 2.0906\n",
      "iter 1040 | loss 2.0810\n",
      "iter 1050 | loss 2.0850\n",
      "[eval] iter 1050 | train 2.0736 | val 2.1429\n",
      "iter 1060 | loss 2.0737\n",
      "iter 1070 | loss 2.0949\n",
      "iter 1080 | loss 1.9751\n",
      "iter 1090 | loss 2.0900\n",
      "iter 1100 | loss 2.0671\n",
      "[eval] iter 1100 | train 2.0766 | val 2.1249\n",
      "iter 1110 | loss 2.0774\n",
      "iter 1120 | loss 2.0585\n",
      "iter 1130 | loss 2.0625\n",
      "iter 1140 | loss 2.0172\n",
      "iter 1150 | loss 2.0908\n",
      "[eval] iter 1150 | train 2.0483 | val 2.0800\n",
      "iter 1160 | loss 2.0685\n",
      "iter 1170 | loss 2.0218\n",
      "iter 1180 | loss 2.0116\n",
      "iter 1190 | loss 2.0341\n",
      "iter 1200 | loss 1.9611\n",
      "[eval] iter 1200 | train 2.0192 | val 2.0785\n",
      "iter 1210 | loss 2.0153\n",
      "iter 1220 | loss 2.0653\n",
      "iter 1230 | loss 2.0447\n",
      "iter 1240 | loss 2.0159\n",
      "iter 1250 | loss 2.0198\n",
      "[eval] iter 1250 | train 2.0090 | val 2.0843\n",
      "iter 1260 | loss 2.0914\n",
      "iter 1270 | loss 1.9913\n",
      "iter 1280 | loss 2.0149\n",
      "iter 1290 | loss 2.0149\n",
      "iter 1300 | loss 1.9539\n",
      "[eval] iter 1300 | train 2.0118 | val 2.0791\n",
      "iter 1310 | loss 1.9197\n",
      "iter 1320 | loss 2.0696\n",
      "iter 1330 | loss 2.0261\n",
      "iter 1340 | loss 1.9909\n",
      "iter 1350 | loss 1.9979\n",
      "[eval] iter 1350 | train 1.9667 | val 2.0524\n",
      "iter 1360 | loss 1.9765\n",
      "iter 1370 | loss 2.0369\n",
      "iter 1380 | loss 2.0275\n",
      "iter 1390 | loss 2.0578\n",
      "iter 1400 | loss 1.9505\n",
      "[eval] iter 1400 | train 1.9885 | val 2.0425\n",
      "iter 1410 | loss 1.9816\n",
      "iter 1420 | loss 2.0351\n",
      "iter 1430 | loss 1.9835\n",
      "iter 1440 | loss 1.9252\n",
      "iter 1450 | loss 1.9591\n",
      "[eval] iter 1450 | train 1.9792 | val 2.0234\n",
      "iter 1460 | loss 1.9834\n",
      "iter 1470 | loss 1.9147\n",
      "iter 1480 | loss 1.8907\n",
      "iter 1490 | loss 1.8979\n",
      "iter 1500 | loss 1.9541\n",
      "[eval] iter 1500 | train 1.9601 | val 2.0137\n",
      "iter 1510 | loss 1.8991\n",
      "iter 1520 | loss 1.9366\n",
      "iter 1530 | loss 1.9346\n",
      "iter 1540 | loss 1.9085\n",
      "iter 1550 | loss 1.8603\n",
      "[eval] iter 1550 | train 1.9014 | val 1.9980\n",
      "iter 1560 | loss 1.8292\n",
      "iter 1570 | loss 1.9180\n",
      "iter 1580 | loss 1.8594\n",
      "iter 1590 | loss 1.9600\n",
      "iter 1600 | loss 1.9411\n",
      "[eval] iter 1600 | train 1.9287 | val 1.9865\n",
      "iter 1610 | loss 1.9506\n",
      "iter 1620 | loss 1.9664\n",
      "iter 1630 | loss 1.8699\n",
      "iter 1640 | loss 1.9048\n",
      "iter 1650 | loss 1.9291\n",
      "[eval] iter 1650 | train 1.9112 | val 2.0005\n",
      "iter 1660 | loss 1.9664\n",
      "iter 1670 | loss 1.8936\n",
      "iter 1680 | loss 1.7842\n",
      "iter 1690 | loss 1.9485\n",
      "iter 1700 | loss 1.9055\n",
      "[eval] iter 1700 | train 1.9038 | val 2.0074\n",
      "iter 1710 | loss 1.9344\n",
      "iter 1720 | loss 1.9362\n",
      "iter 1730 | loss 1.9129\n",
      "iter 1740 | loss 2.0328\n",
      "iter 1750 | loss 1.8992\n",
      "[eval] iter 1750 | train 1.8824 | val 1.9886\n",
      "iter 1760 | loss 1.8796\n",
      "iter 1770 | loss 1.9321\n",
      "iter 1780 | loss 1.8978\n",
      "iter 1790 | loss 1.8554\n",
      "iter 1800 | loss 1.8554\n",
      "[eval] iter 1800 | train 1.8801 | val 1.9688\n",
      "iter 1810 | loss 1.8735\n",
      "iter 1820 | loss 1.9129\n",
      "iter 1830 | loss 1.8748\n",
      "iter 1840 | loss 1.9178\n",
      "iter 1850 | loss 1.8439\n",
      "[eval] iter 1850 | train 1.8455 | val 1.9660\n",
      "iter 1860 | loss 1.8431\n",
      "iter 1870 | loss 1.8474\n",
      "iter 1880 | loss 1.8499\n",
      "iter 1890 | loss 1.9390\n",
      "iter 1900 | loss 1.8400\n",
      "[eval] iter 1900 | train 1.8668 | val 1.9659\n",
      "iter 1910 | loss 1.8486\n",
      "iter 1920 | loss 1.9224\n",
      "iter 1930 | loss 1.7917\n",
      "iter 1940 | loss 1.9043\n",
      "iter 1950 | loss 1.8033\n",
      "[eval] iter 1950 | train 1.8473 | val 1.9679\n",
      "iter 1960 | loss 1.7813\n",
      "iter 1970 | loss 1.7843\n",
      "iter 1980 | loss 1.8454\n",
      "iter 1990 | loss 1.8230\n",
      "iter 2000 | loss 1.8786\n",
      "[eval] iter 2000 | train 1.8353 | val 1.9353\n",
      "iter 2010 | loss 1.8725\n",
      "iter 2020 | loss 1.8783\n",
      "iter 2030 | loss 2.0271\n",
      "iter 2040 | loss 1.8653\n",
      "iter 2050 | loss 1.8866\n",
      "[eval] iter 2050 | train 1.8107 | val 1.9171\n",
      "iter 2060 | loss 1.8439\n",
      "iter 2070 | loss 1.8622\n",
      "iter 2080 | loss 1.7476\n",
      "iter 2090 | loss 1.8479\n",
      "iter 2100 | loss 1.7612\n",
      "[eval] iter 2100 | train 1.8401 | val 1.9253\n",
      "iter 2110 | loss 1.8431\n",
      "iter 2120 | loss 1.8525\n",
      "iter 2130 | loss 1.8093\n",
      "iter 2140 | loss 1.7463\n",
      "iter 2150 | loss 1.7852\n",
      "[eval] iter 2150 | train 1.8070 | val 1.9280\n",
      "iter 2160 | loss 1.9625\n",
      "iter 2170 | loss 1.7953\n",
      "iter 2180 | loss 1.8415\n",
      "iter 2190 | loss 1.8631\n",
      "iter 2200 | loss 1.7994\n",
      "[eval] iter 2200 | train 1.8006 | val 1.9287\n",
      "iter 2210 | loss 1.7704\n",
      "iter 2220 | loss 1.6549\n",
      "iter 2230 | loss 1.8576\n",
      "iter 2240 | loss 1.8697\n",
      "iter 2250 | loss 1.6785\n",
      "[eval] iter 2250 | train 1.7975 | val 1.9078\n",
      "iter 2260 | loss 1.7494\n",
      "iter 2270 | loss 1.8242\n",
      "iter 2280 | loss 1.8517\n",
      "iter 2290 | loss 1.7955\n",
      "iter 2300 | loss 1.7766\n",
      "[eval] iter 2300 | train 1.8010 | val 1.8961\n",
      "iter 2310 | loss 1.7077\n",
      "iter 2320 | loss 1.9038\n",
      "iter 2330 | loss 1.7775\n",
      "iter 2340 | loss 1.7663\n",
      "iter 2350 | loss 1.8865\n",
      "[eval] iter 2350 | train 1.7715 | val 1.8878\n",
      "iter 2360 | loss 1.7858\n",
      "iter 2370 | loss 1.6463\n",
      "iter 2380 | loss 1.8154\n",
      "iter 2390 | loss 1.6855\n",
      "iter 2400 | loss 1.8015\n",
      "[eval] iter 2400 | train 1.7542 | val 1.8992\n",
      "iter 2410 | loss 1.7818\n",
      "iter 2420 | loss 1.7326\n",
      "iter 2430 | loss 1.7762\n",
      "iter 2440 | loss 1.7881\n",
      "iter 2450 | loss 1.8105\n",
      "[eval] iter 2450 | train 1.7629 | val 1.8883\n",
      "iter 2460 | loss 1.7622\n",
      "iter 2470 | loss 1.8025\n",
      "iter 2480 | loss 1.6661\n",
      "iter 2490 | loss 1.8184\n",
      "iter 2500 | loss 1.7690\n",
      "[eval] iter 2500 | train 1.7587 | val 1.8790\n",
      "iter 2510 | loss 1.7814\n",
      "iter 2520 | loss 1.7626\n",
      "iter 2530 | loss 1.7583\n",
      "iter 2540 | loss 1.7279\n",
      "iter 2550 | loss 1.7537\n",
      "[eval] iter 2550 | train 1.7318 | val 1.8765\n",
      "iter 2560 | loss 1.6536\n",
      "iter 2570 | loss 1.7136\n",
      "iter 2580 | loss 1.8092\n",
      "iter 2590 | loss 1.7537\n",
      "iter 2600 | loss 1.7154\n",
      "[eval] iter 2600 | train 1.7481 | val 1.9075\n",
      "iter 2610 | loss 1.7163\n",
      "iter 2620 | loss 1.7530\n",
      "iter 2630 | loss 1.6555\n",
      "iter 2640 | loss 1.7667\n",
      "iter 2650 | loss 1.8133\n",
      "[eval] iter 2650 | train 1.7530 | val 1.8780\n",
      "iter 2660 | loss 1.7540\n",
      "iter 2670 | loss 1.7014\n",
      "iter 2680 | loss 1.8021\n",
      "iter 2690 | loss 1.7113\n",
      "iter 2700 | loss 1.7905\n",
      "[eval] iter 2700 | train 1.7434 | val 1.8730\n",
      "iter 2710 | loss 1.6603\n",
      "iter 2720 | loss 1.7651\n",
      "iter 2730 | loss 1.6393\n",
      "iter 2740 | loss 1.5971\n",
      "iter 2750 | loss 1.7263\n",
      "[eval] iter 2750 | train 1.7308 | val 1.8882\n",
      "iter 2760 | loss 1.7669\n",
      "iter 2770 | loss 1.8251\n",
      "iter 2780 | loss 1.7453\n",
      "iter 2790 | loss 1.6223\n",
      "iter 2800 | loss 1.7695\n",
      "[eval] iter 2800 | train 1.7118 | val 1.8439\n",
      "iter 2810 | loss 1.7351\n",
      "iter 2820 | loss 1.8084\n",
      "iter 2830 | loss 1.6585\n",
      "iter 2840 | loss 1.6838\n",
      "iter 2850 | loss 1.6949\n",
      "[eval] iter 2850 | train 1.6858 | val 1.8512\n",
      "iter 2860 | loss 1.7773\n",
      "iter 2870 | loss 1.6882\n",
      "iter 2880 | loss 1.7495\n",
      "iter 2890 | loss 1.7086\n",
      "iter 2900 | loss 1.6197\n",
      "[eval] iter 2900 | train 1.7028 | val 1.8350\n",
      "iter 2910 | loss 1.7149\n",
      "iter 2920 | loss 1.6431\n",
      "iter 2930 | loss 1.6866\n",
      "iter 2940 | loss 1.6901\n",
      "iter 2950 | loss 1.7881\n",
      "[eval] iter 2950 | train 1.6891 | val 1.8400\n",
      "iter 2960 | loss 1.6934\n",
      "iter 2970 | loss 1.6478\n",
      "iter 2980 | loss 1.6725\n",
      "iter 2990 | loss 1.6975\n",
      "iter 3000 | loss 1.7542\n",
      "[eval] iter 3000 | train 1.6859 | val 1.8155\n",
      "iter 3010 | loss 1.7002\n",
      "iter 3020 | loss 1.5731\n",
      "iter 3030 | loss 1.6756\n",
      "iter 3040 | loss 1.6445\n",
      "iter 3050 | loss 1.7703\n",
      "[eval] iter 3050 | train 1.6988 | val 1.8643\n",
      "iter 3060 | loss 1.6850\n",
      "iter 3070 | loss 1.5671\n",
      "iter 3080 | loss 1.5773\n",
      "iter 3090 | loss 1.7100\n",
      "iter 3100 | loss 1.5985\n",
      "[eval] iter 3100 | train 1.6904 | val 1.8691\n",
      "iter 3110 | loss 1.7742\n",
      "iter 3120 | loss 1.6116\n",
      "iter 3130 | loss 1.6719\n",
      "iter 3140 | loss 1.7170\n",
      "iter 3150 | loss 1.6362\n",
      "[eval] iter 3150 | train 1.6619 | val 1.8360\n",
      "iter 3160 | loss 1.7013\n",
      "iter 3170 | loss 1.5722\n",
      "iter 3180 | loss 1.7449\n",
      "iter 3190 | loss 1.6687\n",
      "iter 3200 | loss 1.5954\n",
      "[eval] iter 3200 | train 1.6897 | val 1.8188\n",
      "iter 3210 | loss 1.6444\n",
      "iter 3220 | loss 1.6766\n",
      "iter 3230 | loss 1.7763\n",
      "iter 3240 | loss 1.6908\n",
      "iter 3250 | loss 1.6884\n",
      "[eval] iter 3250 | train 1.6747 | val 1.8165\n",
      "iter 3260 | loss 1.7141\n",
      "iter 3270 | loss 1.6537\n",
      "iter 3280 | loss 1.7343\n",
      "iter 3290 | loss 1.6762\n",
      "iter 3300 | loss 1.6615\n",
      "[eval] iter 3300 | train 1.6507 | val 1.8294\n",
      "iter 3310 | loss 1.6900\n",
      "iter 3320 | loss 1.6403\n",
      "iter 3330 | loss 1.6934\n",
      "iter 3340 | loss 1.6564\n",
      "iter 3350 | loss 1.6709\n",
      "[eval] iter 3350 | train 1.6501 | val 1.8322\n",
      "iter 3360 | loss 1.7201\n",
      "iter 3370 | loss 1.6994\n",
      "iter 3380 | loss 1.6605\n",
      "iter 3390 | loss 1.6126\n",
      "iter 3400 | loss 1.6046\n",
      "[eval] iter 3400 | train 1.6526 | val 1.8192\n",
      "iter 3410 | loss 1.6453\n",
      "iter 3420 | loss 1.6181\n",
      "iter 3430 | loss 1.5779\n",
      "iter 3440 | loss 1.6200\n",
      "iter 3450 | loss 1.7081\n",
      "[eval] iter 3450 | train 1.6545 | val 1.8103\n",
      "iter 3460 | loss 1.6094\n",
      "iter 3470 | loss 1.7398\n",
      "iter 3480 | loss 1.5555\n",
      "iter 3490 | loss 1.5852\n",
      "iter 3500 | loss 1.6727\n",
      "[eval] iter 3500 | train 1.6576 | val 1.8246\n",
      "iter 3510 | loss 1.5955\n",
      "iter 3520 | loss 1.6287\n",
      "iter 3530 | loss 1.6940\n",
      "iter 3540 | loss 1.6268\n",
      "iter 3550 | loss 1.6469\n",
      "[eval] iter 3550 | train 1.6248 | val 1.7879\n",
      "iter 3560 | loss 1.6959\n",
      "iter 3570 | loss 1.6073\n",
      "iter 3580 | loss 1.6657\n",
      "iter 3590 | loss 1.6075\n",
      "iter 3600 | loss 1.6550\n",
      "[eval] iter 3600 | train 1.6507 | val 1.7871\n",
      "iter 3610 | loss 1.6239\n",
      "iter 3620 | loss 1.6992\n",
      "iter 3630 | loss 1.6227\n",
      "iter 3640 | loss 1.5816\n",
      "iter 3650 | loss 1.6918\n",
      "[eval] iter 3650 | train 1.6218 | val 1.7916\n",
      "iter 3660 | loss 1.7244\n",
      "iter 3670 | loss 1.6122\n",
      "iter 3680 | loss 1.6458\n",
      "iter 3690 | loss 1.5830\n",
      "iter 3700 | loss 1.6442\n",
      "[eval] iter 3700 | train 1.6298 | val 1.7724\n",
      "iter 3710 | loss 1.6791\n",
      "iter 3720 | loss 1.6464\n",
      "iter 3730 | loss 1.5672\n",
      "iter 3740 | loss 1.5946\n",
      "iter 3750 | loss 1.6259\n",
      "[eval] iter 3750 | train 1.6246 | val 1.7625\n",
      "iter 3760 | loss 1.6415\n",
      "iter 3770 | loss 1.5062\n",
      "iter 3780 | loss 1.6271\n",
      "iter 3790 | loss 1.5533\n",
      "iter 3800 | loss 1.4895\n",
      "[eval] iter 3800 | train 1.6315 | val 1.7783\n",
      "iter 3810 | loss 1.6796\n",
      "iter 3820 | loss 1.6496\n",
      "iter 3830 | loss 1.6089\n",
      "iter 3840 | loss 1.6753\n",
      "iter 3850 | loss 1.6949\n",
      "[eval] iter 3850 | train 1.6304 | val 1.7851\n",
      "iter 3860 | loss 1.5720\n",
      "iter 3870 | loss 1.7193\n",
      "iter 3880 | loss 1.5464\n",
      "iter 3890 | loss 1.5931\n",
      "iter 3900 | loss 1.6070\n",
      "[eval] iter 3900 | train 1.6127 | val 1.7926\n",
      "iter 3910 | loss 1.5607\n",
      "iter 3920 | loss 1.6026\n",
      "iter 3930 | loss 1.6140\n",
      "iter 3940 | loss 1.5866\n",
      "iter 3950 | loss 1.5398\n",
      "[eval] iter 3950 | train 1.6188 | val 1.7742\n",
      "iter 3960 | loss 1.6143\n",
      "iter 3970 | loss 1.5718\n",
      "iter 3980 | loss 1.6072\n",
      "iter 3990 | loss 1.6987\n",
      "iter 4000 | loss 1.7018\n",
      "[eval] iter 4000 | train 1.6168 | val 1.7814\n",
      "iter 4010 | loss 1.5427\n",
      "iter 4020 | loss 1.6224\n",
      "iter 4030 | loss 1.6795\n",
      "iter 4040 | loss 1.7249\n",
      "iter 4050 | loss 1.5213\n",
      "[eval] iter 4050 | train 1.5880 | val 1.7759\n",
      "iter 4060 | loss 1.6303\n",
      "iter 4070 | loss 1.4869\n",
      "iter 4080 | loss 1.5608\n",
      "iter 4090 | loss 1.5929\n",
      "iter 4100 | loss 1.6163\n",
      "[eval] iter 4100 | train 1.6206 | val 1.7971\n",
      "iter 4110 | loss 1.5824\n",
      "iter 4120 | loss 1.6357\n",
      "iter 4130 | loss 1.5228\n",
      "iter 4140 | loss 1.5458\n",
      "iter 4150 | loss 1.6175\n",
      "[eval] iter 4150 | train 1.5957 | val 1.7681\n",
      "iter 4160 | loss 1.6268\n",
      "iter 4170 | loss 1.6249\n",
      "iter 4180 | loss 1.5297\n",
      "iter 4190 | loss 1.6226\n",
      "iter 4200 | loss 1.5161\n",
      "[eval] iter 4200 | train 1.5744 | val 1.7746\n",
      "iter 4210 | loss 1.6369\n",
      "iter 4220 | loss 1.5642\n",
      "iter 4230 | loss 1.5977\n",
      "iter 4240 | loss 1.5508\n",
      "iter 4250 | loss 1.6017\n",
      "[eval] iter 4250 | train 1.6038 | val 1.7454\n",
      "iter 4260 | loss 1.6398\n",
      "iter 4270 | loss 1.5915\n",
      "iter 4280 | loss 1.6378\n",
      "iter 4290 | loss 1.6175\n",
      "iter 4300 | loss 1.7386\n",
      "[eval] iter 4300 | train 1.5804 | val 1.7421\n",
      "iter 4310 | loss 1.5595\n",
      "iter 4320 | loss 1.6528\n",
      "iter 4330 | loss 1.6544\n",
      "iter 4340 | loss 1.5140\n",
      "iter 4350 | loss 1.5723\n",
      "[eval] iter 4350 | train 1.5707 | val 1.7462\n",
      "iter 4360 | loss 1.5309\n",
      "iter 4370 | loss 1.5630\n",
      "iter 4380 | loss 1.5505\n",
      "iter 4390 | loss 1.6076\n",
      "iter 4400 | loss 1.5559\n",
      "[eval] iter 4400 | train 1.5664 | val 1.7346\n",
      "iter 4410 | loss 1.6010\n",
      "iter 4420 | loss 1.6138\n",
      "iter 4430 | loss 1.5045\n",
      "iter 4440 | loss 1.6493\n",
      "iter 4450 | loss 1.5991\n",
      "[eval] iter 4450 | train 1.5764 | val 1.7354\n",
      "iter 4460 | loss 1.6138\n",
      "iter 4470 | loss 1.6411\n",
      "iter 4480 | loss 1.4866\n",
      "iter 4490 | loss 1.5904\n",
      "iter 4500 | loss 1.6021\n",
      "[eval] iter 4500 | train 1.5582 | val 1.7495\n",
      "iter 4510 | loss 1.5709\n",
      "iter 4520 | loss 1.6209\n",
      "iter 4530 | loss 1.6134\n",
      "iter 4540 | loss 1.5507\n",
      "iter 4550 | loss 1.5752\n",
      "[eval] iter 4550 | train 1.5731 | val 1.7464\n",
      "iter 4560 | loss 1.5564\n",
      "iter 4570 | loss 1.5113\n",
      "iter 4580 | loss 1.6170\n",
      "iter 4590 | loss 1.5994\n",
      "iter 4600 | loss 1.6280\n",
      "[eval] iter 4600 | train 1.5633 | val 1.7179\n",
      "iter 4610 | loss 1.5374\n",
      "iter 4620 | loss 1.6385\n",
      "iter 4630 | loss 1.6377\n",
      "iter 4640 | loss 1.6130\n",
      "iter 4650 | loss 1.6176\n",
      "[eval] iter 4650 | train 1.5798 | val 1.7378\n",
      "iter 4660 | loss 1.5870\n",
      "iter 4670 | loss 1.5117\n",
      "iter 4680 | loss 1.5580\n",
      "iter 4690 | loss 1.5144\n",
      "iter 4700 | loss 1.6072\n",
      "[eval] iter 4700 | train 1.5567 | val 1.7456\n",
      "iter 4710 | loss 1.5861\n",
      "iter 4720 | loss 1.5537\n",
      "iter 4730 | loss 1.5299\n",
      "iter 4740 | loss 1.6656\n",
      "iter 4750 | loss 1.5475\n",
      "[eval] iter 4750 | train 1.5654 | val 1.7279\n",
      "iter 4760 | loss 1.4891\n",
      "iter 4770 | loss 1.6482\n",
      "iter 4780 | loss 1.5070\n",
      "iter 4790 | loss 1.6199\n",
      "iter 4800 | loss 1.6111\n",
      "[eval] iter 4800 | train 1.5671 | val 1.7303\n",
      "iter 4810 | loss 1.6057\n",
      "iter 4820 | loss 1.6866\n",
      "iter 4830 | loss 1.4195\n",
      "iter 4840 | loss 1.5790\n",
      "iter 4850 | loss 1.6803\n",
      "[eval] iter 4850 | train 1.5906 | val 1.7628\n",
      "iter 4860 | loss 1.5910\n",
      "iter 4870 | loss 1.5615\n",
      "iter 4880 | loss 1.5949\n",
      "iter 4890 | loss 1.6265\n",
      "iter 4900 | loss 1.5178\n",
      "[eval] iter 4900 | train 1.5672 | val 1.7281\n",
      "iter 4910 | loss 1.5699\n",
      "iter 4920 | loss 1.5592\n",
      "iter 4930 | loss 1.5375\n",
      "iter 4940 | loss 1.5766\n",
      "iter 4950 | loss 1.5771\n",
      "[eval] iter 4950 | train 1.5853 | val 1.7228\n",
      "iter 4960 | loss 1.5798\n",
      "iter 4970 | loss 1.4511\n",
      "iter 4980 | loss 1.5281\n",
      "iter 4990 | loss 1.5033\n",
      "iter 5000 | loss 1.6114\n",
      "[eval] iter 5000 | train 1.5352 | val 1.7351\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train (brief run) and plot\n",
    "train_losses, val_losses, steps = [], [], []\n",
    "\n",
    "# Initial eval\n",
    "losses = estimate_loss(model)\n",
    "print(f\"[init] train loss: {losses['train']:.4f}, val loss: {losses['val']:.4f}\")\n",
    "train_losses.append(losses['train'])\n",
    "val_losses.append(losses['val'])\n",
    "steps.append(0)\n",
    "\n",
    "for it in range(1, max_iters + 1):\n",
    "    X, Y = get_batch('train')\n",
    "    logits, loss = model(X, Y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    if it % log_interval == 0:\n",
    "        print(f\"iter {it:4d} | loss {loss.item():.4f}\")\n",
    "\n",
    "    if it % eval_interval == 0:\n",
    "        losses = estimate_loss(model)\n",
    "        print(f\"[eval] iter {it:4d} | train {losses['train']:.4f} | val {losses['val']:.4f}\")\n",
    "        train_losses.append(losses['train'])\n",
    "        val_losses.append(losses['val'])\n",
    "        steps.append(it)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(steps, train_losses, label='train')\n",
    "plt.plot(steps, val_losses, label='val')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.title(f\"Branch: {current_branch()} | device: {device}\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "Thou war to this me honest to their and poor lath\n",
      "The had ere ease to by son, King-corrand, now\n",
      "With guest to death! him not this hornors\n",
      "With chans I answer'd meanus honour to bleed\n",
      "Farewell; let me\n"
     ]
    }
   ],
   "source": [
    "# Quick sampling helper after training\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def sample(model, start: str = \"To be, or\", max_new_tokens: int = 100, temperature: float = 1.0) -> str:\n",
    "    model.eval()\n",
    "    # Load tokenizer metadata if present (char-level uses simple identity)\n",
    "    # For Tiny Shakespeare char-level, meta.pkl includes 'itos' / 'stoi'\n",
    "    import pickle\n",
    "    meta_path = DATA_DIR / 'meta.pkl'\n",
    "    if not meta_path.exists():\n",
    "        print(\"No meta.pkl found; sampling skipped.\")\n",
    "        return \"\"\n",
    "    with open(meta_path, 'rb') as f:\n",
    "        meta = pickle.load(f)\n",
    "    stoi = meta['stoi']\n",
    "    itos = meta['itos']\n",
    "\n",
    "    def encode(s: str):\n",
    "        return [stoi[c] for c in s]\n",
    "\n",
    "    def decode(ids):\n",
    "        return ''.join([itos[i] for i in ids])\n",
    "\n",
    "    idx = torch.tensor([encode(start)], dtype=torch.long, device=device)\n",
    "    with torch.no_grad():\n",
    "        idx = model.generate(idx, max_new_tokens=max_new_tokens, temperature=temperature)\n",
    "    return decode(idx[0].tolist())\n",
    "\n",
    "print(sample(model, start=\"ROMEO:\", max_new_tokens=200, temperature=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
